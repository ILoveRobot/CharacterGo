{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corenlp_xml_reader import AnnotatedText as A\n",
    "from lxml import html\n",
    "from collections import defaultdict\n",
    "# import networkx as nx\n",
    "# import nxpd\n",
    "from wordcloud import WordCloud\n",
    "from utils.file_io_helper import unicode_normalizer,read_books_json\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import os \n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_out(sent):\n",
    "    return ' '.join([w['word'] for w in sent['tokens']])\n",
    "\n",
    "\n",
    "def co_occurence(doc,sentiment):\n",
    "    pair_sent = defaultdict(list)\n",
    "    for sentence in doc.sentences:\n",
    "\n",
    "        curr_name = []\n",
    "        prev_ner = None\n",
    "        for ent in sentence['tokens']:\n",
    "            if ent['ner'] == 'PERSON':\n",
    "                name = ent['word']\n",
    "                size = len(name)\n",
    "                if not prev_ner or prev_ner == name:\n",
    "                    prev_ner = name\n",
    "                else:\n",
    "                    prev_ner += ' ' + name\n",
    "            else:\n",
    "                if prev_ner:\n",
    "                    curr_name.append(prev_ner)\n",
    "                prev_ner = None\n",
    "        if prev_ner:\n",
    "            curr_name.append(prev_ner)\n",
    "            \n",
    "        pair = []\n",
    "        if curr_name:\n",
    "            prev = None\n",
    "            for name_ in curr_name:\n",
    "                if (not prev or prev!=name_) and len(pair)<2:\n",
    "                    pair.append(name_)\n",
    "                    prev = name_\n",
    "            pair = tuple(sorted(pair))\n",
    "            \n",
    "        if len(pair)==2:\n",
    "            pair_sent[pair].append((sentence_out(sentence),sentiment[sentence['id']]))\n",
    "    return pair_sent\n",
    "\n",
    "def xml_analysis(xml_file,limit = 1):\n",
    "    translate = {'Verynegative':-2, 'Negative':-1,'Positive':1,'Verypositive':2,'Neutral':0}\n",
    "    xml = open(xml_file).read()\n",
    "    annotated_text = A(xml)\n",
    "    \n",
    "    tree = html.fromstring(xml)\n",
    "    sentiment = tree.xpath('//sentence/@sentiment')\n",
    "    sentiment = [translate[key] for key in sentiment]\n",
    "\n",
    "    pair_dict =co_occurence(annotated_text,sentiment)\n",
    "    \n",
    "    avg_sent = lambda x:np.mean([y[1] for y in x])\n",
    "    return pair_dict\n",
    "\n",
    "def combine_one_xml(f):\n",
    "    related_sentence_dict = {}\n",
    "    related_sentence_dict[str(os.path.basename(f).split('.')[0])]=xml_analysis(f)\n",
    "    return related_sentence_dict\n",
    "\n",
    "def unpack(lst):\n",
    "    return ' '.join([i[0] for i in lst]), [i[1] for i in lst]      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "related_sent = combine_one_xml('../data/full-text-tag/1.1984_full.txt.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(related_sent['1'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_p={k:unpack(v) for k,v in related_sent['1'].iteritems()} \n",
    "clean_p = [p for p in clean_p if len(p[1])>=7]\n",
    "# clean_p = [pp for p in clean_p for pp in p]\n",
    "# clean_p= [p for p in clean_p if len(p[1]>5)]\n",
    "# docs,sentiments,relations = zip(*clean_p)\n",
    "# relations = [r[0] for r in relations]\n",
    "# docs = list(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Winston', u'Winston KNEW'),\n",
       " (u'Goldstein', u'Parsons'),\n",
       " (u'Tillotson', u'Winston'),\n",
       " (u'Parsons', u'Winston'),\n",
       " (u'Mrs Parsons', u'Parsons'),\n",
       " (u'Ogilvy', u'Winston'),\n",
       " (u'Julia', u'Winston'),\n",
       " (u'B.B.', u'Parsons'),\n",
       " (u'Rutherford', u'Winston'),\n",
       " (u'Charrington', u\"O'Brien\"),\n",
       " (u'Chaucer', u'Shakespeare'),\n",
       " (u'Mrs Parsons', u'Winston'),\n",
       " (u'Charrington', u'Winston'),\n",
       " (u'Julia', u\"O'Brien\"),\n",
       " (u'Aaronson', u'Winston'),\n",
       " (u'Brother', u\"O'Brien\"),\n",
       " (u'B.B.', u'Winston'),\n",
       " (u'Smith', u'Winston'),\n",
       " (u'Norman', u'Winston'),\n",
       " (u'Syme', u'Winston'),\n",
       " (u'Martin', u'Winston'),\n",
       " (u'Julia', u'Katharine'),\n",
       " (u'Charrington', u'Clement'),\n",
       " (u'Julia the story of Winston', u'Winston'),\n",
       " (u\"O'Brien\", u'Winston'),\n",
       " (u'Saint Sebastian', u'Winston'),\n",
       " (u'Katharine', u'Winston'),\n",
       " (u'Winston', u'Withers'),\n",
       " (u'Winston', u'Winston/Smith/Winston Smith'),\n",
       " (u'Goldstein', u'Winston'),\n",
       " (u'Julia Winston', u'Katharine'),\n",
       " (u'Goldstein', u\"O'Brien\"),\n",
       " (u'Smith', u'Winston Smith'),\n",
       " (u'Martin', u\"O'Brien\"),\n",
       " (u'Julia', u\"Julia O'Brien\"),\n",
       " (u'Milton', u'Shakespeare')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
